# üîß CORRECTION MOD√àLE LLAMA3 INEXISTANT

**Date:** 2025-01-27  
**Version:** 1.0  
**Statut:** ‚úÖ **GUIDE DE CORRECTION**

---

## üìã PROBL√àME

**Erreur:** `Mod√®le Ollama introuvable. Le mod√®le "llama3" n'existe pas.`

**Cause:** Le mod√®le `llama3` n'existe pas dans Ollama Cloud. Il faut utiliser `llama3.1` ou un autre mod√®le valide.

---

## ‚úÖ SOLUTION

### Option 1: Supprimer OLLAMA_MODEL (Recommand√©)

Si vous avez configur√© `OLLAMA_MODEL=llama3` dans Supabase Secrets, supprimez-le :

```bash
# Supprimer OLLAMA_MODEL pour utiliser le mod√®le par d√©faut (gpt-oss:120b-cloud)
supabase secrets unset OLLAMA_MODEL
```

**R√©sultat:** L'Edge Function utilisera `gpt-oss:120b-cloud` par d√©faut.

---

### Option 2: Configurer un mod√®le valide

Si vous voulez utiliser un mod√®le sp√©cifique, configurez un mod√®le valide :

```bash
# Utiliser gpt-oss:120b-cloud (recommand√© - par d√©faut)
supabase secrets set OLLAMA_MODEL=gpt-oss:120b-cloud

# OU utiliser gpt-oss:20b-cloud (plus rapide, moins puissant)
supabase secrets set OLLAMA_MODEL=gpt-oss:20b-cloud

# OU utiliser qwen3-coder:480b-cloud
supabase secrets set OLLAMA_MODEL=qwen3-coder:480b-cloud

# OU utiliser deepseek-v3.1:671b-cloud
supabase secrets set OLLAMA_MODEL=deepseek-v3.1:671b-cloud
```

---

## üìö MOD√àLES VALIDES

**Mod√®les qui existent dans Ollama Cloud:**
- ‚úÖ `gpt-oss:120b-cloud` (recommand√© - par d√©faut)
- ‚úÖ `gpt-oss:20b-cloud`
- ‚úÖ `qwen3-coder:480b-cloud`
- ‚úÖ `deepseek-v3.1:671b-cloud`

**Mod√®les qui N'EXISTENT PAS:**
- ‚ùå `llama3` (n'existe pas)
- ‚ùå `llama3.1` (n'existe pas)
- ‚ùå `llama3.2` (n'existe pas)
- ‚ùå `llama2` (n'existe pas sur Ollama Cloud)
- ‚ùå `mistral` (n'existe pas sur Ollama Cloud)

---

## üîß ACTIONS REQUISES

### 1. V√©rifier les secrets actuels

```bash
supabase secrets list
```

**V√©rifier:**
- Si `OLLAMA_MODEL` existe avec la valeur `llama3`, **supprimez-le** ou **corrigez-le**

---

### 2. Supprimer ou corriger OLLAMA_MODEL

```bash
# Option A: Supprimer (utilisera llama3.1 par d√©faut)
supabase secrets unset OLLAMA_MODEL

# Option B: Corriger avec un mod√®le valide
supabase secrets set OLLAMA_MODEL=gpt-oss:120b-cloud
```

---

### 3. Red√©ployer l'Edge Function (optionnel)

```bash
cd application
supabase functions deploy llama-proxy-ollama-cloud
```

---

## üîç V√âRIFICATION

### 1. V√©rifier les logs Supabase

Apr√®s avoir corrig√©, les logs devraient afficher :

```
[llama-proxy-ollama-cloud] Mod√®le: gpt-oss:120b-cloud
[llama-proxy-ollama-cloud] R√©ponse Ollama re√ßue
```

Au lieu de :

```
[llama-proxy-ollama-cloud] Mod√®le: llama3
[llama-proxy-ollama-cloud] Erreur Ollama: 404 {"error": "model 'llama3' not found"}
```

---

### 2. Tester l'application

1. Utilisez l'application mobile
2. Essayez de g√©n√©rer une analyse du journal
3. L'erreur devrait √™tre r√©solue

---

## ‚ö†Ô∏è NOTES IMPORTANTES

1. **Le mod√®le par d√©faut est `gpt-oss:120b-cloud`** ‚úÖ
2. **Le mod√®le `llama3` n'existe pas** ‚ùå
3. **V√©rifiez toujours que le mod√®le existe** avant de le configurer

---

## üìö R√âF√âRENCES

- **Guide de configuration:** `CONFIGURER_CLE_OLLAMA.md`
- **Troubleshooting:** `TROUBLESHOOTING_OLLAMA_EDGE_FUNCTION.md`
- **Ollama Cloud:** [https://ollama.com](https://ollama.com)

---

**Derni√®re mise √† jour:** 2025-01-27

